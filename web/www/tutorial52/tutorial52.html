<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title> Tutorial 52 - Vulkan First Triangle</title>

    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:400,600">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="../print.css" media="print">
</head>
<body>
    <header id="header">
        <div>
            <h2> Tutorial 52: </h2>
            <h1> Vulkan First Triangle  </h1>
        </div>

        <a id="logo" class="small" href="../../index.html" title="Homepage">
            <img src="..//logo ldpi.png">
        </a>
    </header>

<article id="content" class="breakpoint">
<section>
            <h3> Background </h3>
<p>
In the previous tutorial we learned how to clear the window and were introduced to a couple of Vulkan
    entities, the swap chain the the command buffer, that are key parts of that operation. Today we are going
    to render our first triangle. This will require the introduction of four new Vulkan entities - the image view,
    render pass, framebuffer and pipeline. Shaders are also required but since they play the same role as
    in OpenGL programmable pipeline, I don't consider them a new entity. If you are not familiar with shaders
    make sure you study tutorial 4 before continuing.
</p>
<p>
    Let's start with the largest new object introduced by this tutorial - the <i>pipeline</i>. Actually, the full name is
    the <i>graphics pipeline</i> because in addition to graphics Vulkan takes the compute field very seriously. In general, the compute
    field comprises of many algorithms that are not 3D in nature (they are not based on the way GPUs process triangles) but they
    can be accelerated by the distributive power of the GPUs. This is why the Vulkan spec specifies both a graphics pipeline and
    a compute pipeline. In this tutorial we are going to use only the graphics pipeline. The graphics pipeline object holds
    most of the state that is already familiar to us from standard OpenGL.
</p>
</section>

<section>
  <h3> Source walkthru </h3>
      <pre><code>
class OgldevVulkanApp
{
public:

    OgldevVulkanApp(const char* pAppName);
    
    ~OgldevVulkanApp();
    
    void Init();    
    
    void Run();
    
private:

    void CreateSwapChain();
    void CreateCommandBuffer();
    void RecordCommandBuffers();
    void RenderScene();
<b>    void CreateRenderPass();
    void CreateFramebuffer();
    void CreateShaders();
    void CreatePipeline();</b>

    std::string m_appName;
    VulkanWindowControl* m_pWindowControl;
    OgldevVulkanCore m_core;    
    std::vector<VkImage> m_images;
    VkSwapchainKHR m_swapChainKHR;
    VkQueue m_queue;
    std::vector<VkCommandBuffer> m_cmdBufs;
    VkCommandPool m_cmdBufPool;
<b>    std::vector<VkImageView> m_views;	
    VkRenderPass m_renderPass;
    std::vector<VkFramebuffer> m_fbs;
    VkShaderModule m_vsModule;
    VkShaderModule m_fsModule;
    VkPipeline m_pipeline;
    VkPipelineLayout m_pipelineLayout;</b>
};
</code></pre>
  <p>
    This is the updated main class of the tutorial. Highlighted we can see the four new private methods that were added in order to create the new objects
    and their respective members to hold the relevant handles.
    </p>
    <pre><code>
void OgldevVulkanApp::Init()
{
#ifdef WIN32
    m_pWindowControl = new Win32Control(m_appName.c_str());
#else
    m_pWindowControl = new XCBControl();
#endif
    m_pWindowControl->Init(WINDOW_WIDTH, WINDOW_HEIGHT);

    m_core.Init(m_pWindowControl);

    vkGetDeviceQueue(m_core.GetDevice(), m_core.GetQueueFamily(), 0, &m_queue);

    CreateSwapChain();
    CreateCommandBuffer();
<b>    CreateRenderPass();
    CreateFramebuffer();
    CreateShaders();
    CreatePipeline();</b>
    RecordCommandBuffers();
}

</code></pre>
<p>
Let's review the changes top to bottom. The first thing we need to do is add functions to create the four new types of objects. The new functions that were added on top
    of the material of the previous tutorial are marked in bold face above. We will start with the creation of the render pass.
</p>
<pre><code>
void OgldevVulkanApp::CreateRenderPass()
{
    VkAttachmentReference attachRef = {};
    attachRef.attachment = 0;
    attachRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL;
<br>
    VkSubpassDescription subpassDesc = {};
    subpassDesc.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS;
    subpassDesc.colorAttachmentCount = 1;
    subpassDesc.pColorAttachments = &attachRef;
</code></pre>
<p>
  In order to create a render pass we will need to populate a structure called VkRenderPassCreateInfo. This is a complex structure that points to several sub-structs. Most importantly, it points to a struct that specifies
  the attachments and subpasses. Attachments are resources connected to the pipeline and subpasses represent a series of draw commands that all read or write to the same collection of attachments. 
  </p>
<p>
    The subpass description struct specifies a collection of attachments that take part in the subpass.
    This collection includes color, depth/stencil and multisample attachments. In our single subpass description struct we first specify that we are binding this subpass to the graphics pipeline (rather than the compute).
    Then we specify that we have just one color attachment that we are going to render to and we set the pColorAttachments to point to the descriptor
    of that attachments (in the case of multiple color attachments this would have been a descriptor array). We don't have any other type of attachment here so all
    the other attachment count members remain zero. 
</p>
<p>
    All the attachments that the subpass descriptor can point to have the VkAttachmentReference struct type. This struct has just two members. The first member, titled 'attachments', is an index into the
    renderPassCreateInfo.pAttachments below. Basically the render pass create info struct points to an array of attachements and all the attachments specified in the subpasses are
    just indices into that array. We have just one attachment here so the index in our case is zero. The other member in the VkAttachmentReference struct is the layout of the attachment. This allows us to indicate that the attachment will only be used as
    the target of rendering or as a shader input resource and allows the driver to plan ahead accordingly.
</p>
<p>
  We now have a descriptor of a single subpass which points to a single attachment. Now we must specify all the attachments in the render pass as a single array. The attachments from the subpass are simply indices into this array
  so the actuul data for each attachment is in a single locations.
  </p>
<pre><code>
    VkAttachmentDescription attachDesc = {};
    attachDesc.format = m_core.GetSurfaceFormat().format;
    attachDesc.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR;
    attachDesc.storeOp = VK_ATTACHMENT_STORE_OP_STORE;
    attachDesc.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE;
    attachDesc.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE;
    attachDesc.initialLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;
    attachDesc.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR;

    VkRenderPassCreateInfo renderPassCreateInfo = {};
    renderPassCreateInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO;
    renderPassCreateInfo.attachmentCount = 1;
    renderPassCreateInfo.pAttachments = &attachDesc;
    renderPassCreateInfo.subpassCount = 1;
    renderPassCreateInfo.pSubpasses = &subpassDesc;
</code></pre>
<p>
In the render pass create info struct we specify that we have one attachment and one subpass. We also specify the
    addresses of the corresponding structures that describe the attachment and subpass (if we had more than one then 'attachDesc'
    and 'subpassDesc' would have been arrays of structs).
</p>
<p>
    Let's review the members in the VkAttachmentDescription structure.
    <ul>
        <li>
            <b>'format'</b> is simply the format of the image used for the
            attachment. We grab it from the surface we created as part of the core (see <a href="../tutorial50/tutorial50.html">tutorial 50</a>). </li>
        <li>
            <b>'loadOp'</b> specifies whether we preserve or clear the previous contents in the color and depth buffers (we don't need the old contents so we go with clear).
        </li>
        <li>
            <b>'storeOp'</b> specifies whether the content we will generate in the render pass will be stored to the color and depth buffers or be discarded (store in our case).
        </li>
        <li>
            <b>'stencilLoadOp'/'stencilStoreOp'</b> is the same as the above two but for the stencil buffer. We are not using stencil here so we set it to 'don't care'.
        </li>
        <li>
            <b>'initialLayout'/'finalLayout'</b> - images in Vulkan are stored in an implementationn defined layout which is opaque to us. This means that we don't know how the images
            pixels are structured in the physical memory that contains them. What Vulkan does is to provide a few image usage types (a.k.a <i>layouts</i>) that allows the
            programmer to specify how the image will be used. Each GPU vender can then map this to the most optimal method of storing the image in memory. We can often transition
            an image from one layout to another. The attributes 'initialLayout'/'finalLayout' specify in what layout the image will be at the start of the render pass and the
            layout they will transition to when the render pass ends. In our case we start and end with the "presentable" layout.
        </li>
    </ul>
</p>
<pre><code>
    VkResult res = vkCreateRenderPass(m_core.GetDevice(), &renderPassCreateInfo, NULL, &m_renderPass);
    CHECK_VULKAN_ERROR("vkCreateRenderPass error %d\n", res);
}
</code></pre>
<p>
    Finally, the call to create the render pass is very simple - it takes the device, the address of the create info struct, an allocator (NULL in our case)
    and returns the handle to the render pass object in the last parameter.
</p>
<pre><code>
void OgldevVulkanApp::CreateSwapChain()
{          
    . . .
    m_images.resize(NumSwapChainImages);
    m_cmdBufs.resize(NumSwapChainImages);
<b>    m_views.resize(NumSwapChainImages);</b>
    . . .
}
</code></pre>
  <p>
    We are going to see how to create the framebuffer but to make sure it doesn't crash on us let's first
    resize the m_views members (vector of image views) to the same number as our images and command buffers.
    This will be used in the next function. This is the only change required in the creation of the swap chain.
    </p>
<pre><code>
void OgldevVulkanApp::CreateFramebuffer()
{
    m_fbs.resize(m_images.size());
</code></pre>
<p>
    We need to prepare a framebuffer object for every image so the first thing we do here is to resize the
    framebuffer vector to match the number of images.
  </p>
  <p>
    Now lets loop and create the framebuffers. Objects in the pipeline (e.g. shaders) cannot access resources directly.
    In intermediate entity called an <i>Image View</i> sits between the image and whoever needs to access it.
    The image view represents a continuous range of image subresources and provides more metadata for accessing.
    Therefore, we need to create an image view in order for the framebuffer to be able to access the image. We will
    create an image view for each image and a framebuffer for each image view.
  </p>
  <pre><code>
    for (uint i = 0 ; i < m_images.size() ; i++) {
        VkImageViewCreateInfo ViewCreateInfo = {};
        ViewCreateInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO;
        ViewCreateInfo.image = m_images[i];
        ViewCreateInfo.format = m_core.GetSurfaceFormat().format;
        ViewCreateInfo.viewType = VK_IMAGE_VIEW_TYPE_2D;
        ViewCreateInfo.components.r = VK_COMPONENT_SWIZZLE_IDENTITY;
        ViewCreateInfo.components.g = VK_COMPONENT_SWIZZLE_IDENTITY;
        ViewCreateInfo.components.b = VK_COMPONENT_SWIZZLE_IDENTITY;
        ViewCreateInfo.components.a = VK_COMPONENT_SWIZZLE_IDENTITY;
        ViewCreateInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT;
        ViewCreateInfo.subresourceRange.baseMipLevel = 0;
        ViewCreateInfo.subresourceRange.levelCount = 1;
        ViewCreateInfo.subresourceRange.baseArrayLayer = 0;
        ViewCreateInfo.subresourceRange.layerCount = 1;

        VkResult res = vkCreateImageView(m_core.GetDevice(), &ViewCreateInfo, NULL, &m_views[i]);
	CHECK_VULKAN_ERROR("vkCreateImageView error %d\n", res);
			  </code></pre>
<p>
  We populate the VkImageViewCreateInfo struct with several fields: the handle to the image view, format (which we take from our core objects)
  and view type which says how we look at the image (for example, we can create an image of the cube type and access only one face as a 2D image).
  There is also a components member that allows remapping of the RGBA channels (which we are not interested in so we set to the default). Finally,
  we have a subresourceRange struct that defines the range of subresources that can be accessed. We will revisit this in the future so for now we keep
  it as simple as possible (no mip-mapping, no arrays, etc). 
  </p>
  <pre><code>
        VkFramebufferCreateInfo fbCreateInfo = {};
        fbCreateInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO;
        fbCreateInfo.renderPass = m_renderPass;
        fbCreateInfo.attachmentCount = 1;
        fbCreateInfo.pAttachments = &m_views[i];
        fbCreateInfo.width = WINDOW_WIDTH;
        fbCreateInfo.height = WINDOW_HEIGHT;
        fbCreateInfo.layers = 1;

        res = vkCreateFramebuffer(m_core.GetDevice(), &fbCreateInfo, NULL, &m_fbs[i]);
        CHECK_VULKAN_ERROR("vkCreateFramebuffer error %d\n", res);	
    }
}
</code></pre>
<p>
  Once the image view has been created we can create a framebuffer object that points to it. Notice that both the render pass
  and the framebuffer has a notion of an attachment. But where the framebuffer contains references to the actual resource (via image view),
  the render pass only contains indices into the framebuffer which is currently active. We will see later how the framebuffer is used.
  </p>
</section>

</article>

<script src="../html5shiv.min.js"></script>
<script src="../html5shiv-printshiv.min.js"></script>

<div id="disqus_thread"></div>
<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'ogldevatspacecouk'; // required: replace example with your forum shortname
var disqus_url = 'http://ogldev.atspace.co.uk/www/tutorial52/tutorial52.html';

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

</body>
</html>
